[{"content":"Overview Exploring how to group and execute different categories of tests using rust and cargo.\nBackground In the second half of 2024, I spent sometime going over the Zero To Production In Rust Book while learning how to use rust to build services. Naturally, I took some of the ideas in the book and gave it my own slight spin based on my past experience. One of these areas was in testing and namely how to test the services at different levels.\nBefore we go any further, lets talk about the nomenclature in this blog. This nomenclature is not meant to be 100% industry standard but rather a way to have common language around what is that I am describing.\nNomenclature integration tests A test that evaluates more than one code unit / module in a rust project. In rust, these tests typically reside in the tests/ directory. The parent directory is the one that contains the cargo.toml file\nExample:\nservice/ lib/ \u0026lt;-- the application logic as a \u0026#34;library\u0026#34; bin/ \u0026lt;-- the executable binary of the service. Instantiates the lib (more on this later) tests/ \u0026lt;-- integration tests live here Cargo.toml Theses tests call some entry point in the lib/ directory and all the subsequent code paths from that entry-point.\nend-to-end tests This form of testing does not rely on invoking the rust entry-point directly (like with integration tests). Rather, it relies on calling the running service[s]. This form of testing is helpful to make sure that the pipes across the different components of your services work as expected when the service is running.\nIf we take the example of http-based service and say it had the following attributes\nservice http://localhost:3030/GetUser - Under the hood, this endpoint calls the entrypoint method `pub get_user` method in the `lib/` directory Integration tests would call that entry-point method (because it is public). End-to-end tests would call the localhost:3030/GetUser of the running service\nWhat is the issue? The cargo tool-chain comes with good, sane defaults. Writing lib integration tests is as easy as running\n$ cargo test --test \u0026#39;*\u0026#39; Note: The above command runs all integration tests in the tests/ sub-directory.\nThis works for almost all use cases, but for the case we described above, its not as intuitive how to denote some tests as integration tests separate from end-to-end tests\nHow can we get around this? We can define a test harness in the Cargo.toml file for each type of test we care about. As an example say we had the following folder structure\nservice/ ... tests/ integration/ mod.rs test_integration_a.rs test_integration_b.rs endtoend/ mod.rs test_e2e_a.rs test_e2e_b.rs Cargo.toml Note: test file names are only for example purposes\nAnd each of the test files has a function marked as\n#[test] fn testSomething() { // ... } and/or\n#[cfg(test)] mod group_of_tests { //.. } These tests can be part of mod of there respective directory. In the case of endtoend/ in our example, the mod.rs file would look like so\nmod test_e2e_a; mod test_e2e_b; And the test harness in Cargo.toml would be defined as\n[[test]] name = \u0026#34;integration\u0026#34; path = \u0026#34;tests/integration/mod.rs\u0026#34; test = true [[test]] name = \u0026#34;endtoend\u0026#34; path = \u0026#34;tests/endtoend/mod.rs\u0026#34; test = true Executing each kind of test With plain cargo\n$ cargo test --test integration With nextest\n$ cargo nextest run --test integration Final thoughts Some of this may sound overkill. For most projects this is likely the case but it is a good strategy to keep in your back pocket if you want to logically group and execute tests.\n","permalink":"//localhost:1313/posts/beyond-integration-tests-in-rust/","summary":"Exploring how to group and execute a collection of related tests in Rust","title":"Beyond Integration Tests in Rust"},{"content":"Background My name is Yaadata (pronounced ya-duh-tah), or Yadi. With a degree in Chemical and Bio-molecular Engineering, I\u0026rsquo;ve spent 12 years coding, 6 of those years professionally. My specialization is in high-throughput, low-latency distributed systems but I carry other interests such as\nStatistical trading systems Developer productivity tooling Software Design Professional Experience Summary Built enterprise systems using Go, Java, JavaScript, with expertise in: Transaction Processing (PostgreSQL, CockroachDB, MySQL, DynamoDB)\nAnalytics Processing.\nData Processing and Message Passing\nImplemented saga pattern solutions for payment systems: Choreography pattern for member entity and card transaction processing Orchestration pattern for FedNow and ACH payment reversals Proficient in system-wide performance optimization and troubleshooting across network, application, and database layers Resume Click to View Previous Next \u0026nbsp; \u0026nbsp; / [pdf] View the PDF file here. ","permalink":"//localhost:1313/about/","summary":"\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cp\u003eMy name is \u003cem\u003eYaadata\u003c/em\u003e (pronounced ya-duh-tah), or \u003cem\u003e\u003cstrong\u003eYadi\u003c/strong\u003e\u003c/em\u003e. With a degree in Chemical and Bio-molecular Engineering, I\u0026rsquo;ve spent 12 years coding,  6 of those years professionally. My specialization is in high-throughput, low-latency distributed systems but I carry other interests such as\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStatistical trading systems\u003c/li\u003e\n\u003cli\u003eDeveloper productivity tooling\u003c/li\u003e\n\u003cli\u003eSoftware Design\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"professional-experience\"\u003eProfessional Experience\u003c/h3\u003e\n\u003ch4 id=\"summary\"\u003eSummary\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eBuilt enterprise systems using Go, Java, JavaScript, with expertise in:\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTransaction Processing (PostgreSQL, CockroachDB, MySQL, DynamoDB)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAnalytics Processing.\u003c/p\u003e","title":"About"}]